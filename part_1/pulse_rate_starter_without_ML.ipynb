{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description** :\n",
    "    - Run the code cell below to check the performance of the algorithm on the training data.\n",
    "    - Testing data are available in the directory datasets/troika/testing_data if you'd like to see the performance of the model on new data.\n",
    "    \n",
    "> - **Data Description** :\n",
    "    - ECG signals have one channel.\n",
    "    - PPG signals have two channels. we take the second channel as it poses the more challenging problem and suggested. Here in the problem i have taken second channel which is suggested.\n",
    "    - Accelerometers have three channels, each corresponding to a space axis x, y, and z. I use the magnitude of these three channels as distance calculation.\n",
    "    - The data is 125Hz sampled from 12 different subjects.\n",
    "\n",
    "> - **Algorithhm Description** :\n",
    "    - Fast Fourier Transformation to the PPG and IMU signals.\n",
    "    - Find two strongest frequencies from the PPG data.\n",
    "    - Find the peaks of PPG frequencies.\n",
    "    - If no peak was found, simply get the strongest frequency and use it as the EEG estimation.\n",
    "    - If the distance of magnitutes between these two frequencies is small, perform the following algorithm to choose the best peak:\n",
    "    - For each peak of the Fast-Fourier Transformed IMU spectrums, see how close it is is to each peak of the PPG spectrums.\n",
    "    - Choose the closest peak's PPG frequency as the estimation.\n",
    "    - If there is only a single peak, use the frequency of that peak as the EEG estimation\n",
    "\n",
    ">   - **the specific aspects of the physiology that it takes advantage of** : PPG signals can be used for measuring heart rate. Capillaries in the wrist fill with blood when the ventricles contract, when the blood passes light emitted by the PPG sensor is absorbed by red blood cells in these capillaries and the photodetector will see the cut in reflected light. Change in light measures and this oscillating waveform is the pulse rate.\n",
    "\n",
    ">   - **describtion of the algorithm outputs** : \n",
    "    - Outputs: the estimated frequency (in BPM) and the confidence score of that prediction.\n",
    "\n",
    ">   - **caveats on algorithm outputs** : The confidence rate is only calculated based on the magnitude of a small area that contains the estimated spectral frequency relative to the sum magnitude of the entire spectrum. \n",
    "\n",
    ">   - **common failure modes** : When the PPG picks a higher frequency signal that is not from the heart rate. This is possible due to hand movements, arm movement, alivation. To overcome with this, the accelerations measurmnet use in the algorithm.\n",
    "\n",
    "> - **Algorithm Performance** :\n",
    "    - The performance was calculated by calculating the mean absolute error between the HR estimation and the reference HR from the ECG sensors at 90% availability. Put another way, 90% of the best estimates according to the algorithm's confidence scores.\n",
    "    - The error of the model in the testing data is 0.60\n",
    "\n",
    "The algorithm requires its parameters to have the exact values that are currently used as reference to the desired low error score. To improve performance, a machine learning approach can be usefull, with also more test subjects performing various kinds of different activities. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20.168551153481324"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate():\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "        # Compute aggregate error metric\n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "fs = 125\n",
    "window_len_s = 10\n",
    "window_shift_s = 2\n",
    "past_window = 3\n",
    "pass_band = (40/60.0, 240/60.0)\n",
    "multiplier = 4\n",
    "ppg_mag_height = 0.55\n",
    "acc_mag_height = 0.3\n",
    "ppg_min_dist = 0.2\n",
    "num_best = 2\n",
    "acc_num_best_arg = 2\n",
    "\n",
    "def bandpass_filter(signal):\n",
    "    b, a = scipy.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return scipy.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def get_indxs(sig_len, ref_len):\n",
    "    \n",
    "    if ref_len < sig_len:\n",
    "        n = ref_len\n",
    "    else:\n",
    "        n = sig_len\n",
    "    \n",
    "    start_indxs = (np.cumsum(np.ones(n) * fs * window_shift_s) - fs * window_shift_s).astype(int)\n",
    "    end_indxs = start_indxs + window_len_s * fs\n",
    "    \n",
    "    return (start_indxs, end_indxs)\n",
    "\n",
    "def Predict(ppg, accx, accy, accz):\n",
    "    \n",
    "    ppg = bandpass_filter(ppg)        \n",
    "    accx = bandpass_filter(accx)\n",
    "    accy = bandpass_filter(accy)\n",
    "    accz = bandpass_filter(accz)\n",
    "        \n",
    "    n = len(ppg) * multiplier\n",
    "    freqs = np.fft.rfftfreq(n, 1/fs)\n",
    "\n",
    "    fft = np.abs(np.fft.rfft(ppg, n))\n",
    "    fft[freqs <= pass_band[0]] = 0.0\n",
    "    fft[freqs >= pass_band[1]] = 0.0\n",
    "\n",
    "    acc_l2 = np.sqrt(accx ** 2 + accy ** 2 + accz ** 2)\n",
    "\n",
    "    acc_fft = np.abs(np.fft.rfft(acc_l2, n))\n",
    "    acc_fft[freqs <= pass_band[0]] = 0.0\n",
    "    acc_fft[freqs >= pass_band[1]] = 0.0\n",
    "\n",
    "\n",
    "    peaks, _ = scipy.signal.find_peaks(fft, height=ppg_mag_height*np.max(fft), distance=1)\n",
    "    max_ppg_fs = freqs[peaks]\n",
    "\n",
    "    acc_peaks, _ = scipy.signal.find_peaks(acc_fft, height=acc_mag_height*np.max(acc_fft), distance=50)\n",
    "    max_acc_fs = freqs[acc_peaks]\n",
    "    max_acc_ids = []\n",
    "    \n",
    "    if len(max_ppg_fs) == 0:\n",
    "        best_fit = freqs[np.argmax(fft)]\n",
    "        \n",
    "    elif len(max_ppg_fs) > 1:\n",
    "        max_ppg_ids = np.argpartition(fft[peaks], -num_best)[-num_best:]\n",
    "        max_ppg_ids = max_ppg_ids[np.argsort(-fft[peaks][max_ppg_ids])]\n",
    "        max_ppg_fs = max_ppg_fs[max_ppg_ids]\n",
    "    \n",
    "        best_fit = max_ppg_fs[0]\n",
    "        \n",
    "        ppg_best_distance = fft[peaks][max_ppg_ids[0]] - fft[peaks][max_ppg_ids[1]] # Here change\n",
    "        ppg_best_distance = ppg_best_distance/1000\n",
    "        ppg_min_dist_val = fft[peaks][max_ppg_ids[0]] * ppg_min_dist\n",
    "        if len(acc_peaks) > 0 and ppg_best_distance < ppg_min_dist_val:\n",
    "            if len(acc_peaks) < acc_num_best_arg:\n",
    "                acc_num_best = len(acc_peaks)\n",
    "            else:\n",
    "                acc_num_best = acc_num_best_arg\n",
    "            max_acc_ids = np.argpartition(acc_fft[acc_peaks], -acc_num_best)[-acc_num_best:]\n",
    "            max_acc_ids = max_acc_ids[np.argsort(-acc_fft[acc_peaks][max_acc_ids])]\n",
    "            max_acc_fs = max_acc_fs[max_acc_ids] \n",
    "            \n",
    "            if max_acc_fs[0] == best_fit:\n",
    "                if max_ppg_fs[0]< max_ppg_fs[1]:\n",
    "                    best_fit = max_ppg_fs[1]\n",
    "\n",
    "            closest_i = 0\n",
    "            closest_dist = np.inf\n",
    "            for i in range(num_best):\n",
    "                dist = 0\n",
    "                if closest_dist > dist:\n",
    "                    for j in range(acc_num_best):\n",
    "                        dist_j = np.abs(max_acc_fs[j] - max_ppg_fs[i])\n",
    "                        dist += dist_j\n",
    "\n",
    "                    closest_dist = dist\n",
    "                    closest_i = i\n",
    "            best_fit = max_ppg_fs[closest_i]\n",
    "    else:\n",
    "        best_fit = max_ppg_fs[0]\n",
    "        \n",
    "    fs_win = 45  / 60.0\n",
    "    fs_win_e = (freqs >= best_fit - fs_win) & (freqs <= best_fit +fs_win)\n",
    "    conf = np.sum(fft[fs_win_e])/np.sum(fft)\n",
    "    \n",
    "    est = best_fit * 60\n",
    "    \n",
    "    return (est, conf)\n",
    "\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl, log_vars=True):\n",
    "    \"\"\"\n",
    "    Run Pulse Rate Algorithm\n",
    "    \n",
    "    Loads data and model, then calculate errors and confidence rates from the data.\n",
    "    \n",
    "    Args:\n",
    "        data_fl: (string) Path to data file (MATLAB data)\n",
    "        ref_fl: (string) Path to reference data file (MATLAB data)\n",
    "        log_vars: (bool) If True, log some variables in the `log` object for further analysis\n",
    "        \n",
    "    Returns:\n",
    "        (np.array) Error scores\n",
    "        (np.array) Confidence rates\n",
    "    \"\"\"\n",
    "\n",
    "    signals = scipy.io.loadmat(data_fl)['sig']\n",
    "    references = scipy.io.loadmat(ref_fl)['BPM0'].reshape(-1)\n",
    "    \n",
    "    errors = []\n",
    "    confidence = []\n",
    "    estimations = []\n",
    "    \n",
    "    start_idxs, end_idxs = get_indxs(signals.shape[1], len(references))\n",
    "    \n",
    "    for i, start_idx in enumerate(start_idxs):\n",
    "        end_idx = end_idxs[i]\n",
    "        ref = references[i]\n",
    "        \n",
    "        ppg = signals[2, start_idx:end_idx]\n",
    "        accx = signals[3, start_idx:end_idx]\n",
    "        accy = signals[4, start_idx:end_idx]\n",
    "        accz = signals[5, start_idx:end_idx]\n",
    "        \n",
    "        est, conf = Predict(ppg, accx, accy, accz)\n",
    "\n",
    "        error = np.abs(est - ref)\n",
    "\n",
    "        errors.append(error)\n",
    "        confidence.append(conf)\n",
    "        estimations.append(est)\n",
    "    \n",
    "    return np.array(errors), np.array(confidence)\n",
    "Evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
